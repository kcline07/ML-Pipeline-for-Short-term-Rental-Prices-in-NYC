diff --git a/components/conda.yml b/components/conda.yml
index 7210a07..eef19fb 100644
--- a/components/conda.yml
+++ b/components/conda.yml
@@ -2,12 +2,12 @@ name: components
 channels:
   - conda-forge
   - defaults
+
 dependencies:
-  - python=3.10
-  - pyyaml
-  - hydra-core=1.3.2
-  - pytest
-  - pip
+  - mlflow=2.1.1
+  - pyyaml=5.3.1
+  - hydra-core=1.0.6
+  - pip=20.3.3
   - pip:
-      - mlflow==2.8.1
-      - wandb==0.16.0
\ No newline at end of file
+      - wandb==0.13.9
+      - databricks_cli==0.8.7
\ No newline at end of file
diff --git a/components/test_regression_model/conda.yml b/components/test_regression_model/conda.yml
index 6b8abbc..f57f3f5 100644
--- a/components/test_regression_model/conda.yml
+++ b/components/test_regression_model/conda.yml
@@ -6,7 +6,7 @@ dependencies:
   - python=3.10.0
   - pip=23.3.1
   - requests=2.24.0
-  - scikit-learn=1.3.2
+  - scikit-learn=1.5.2
   - pandas=2.1.3
   - pip:
       - mlflow==2.8.1
diff --git a/conda.yml b/conda.yml
index 81bb14c..1bb21d0 100644
--- a/conda.yml
+++ b/conda.yml
@@ -1,12 +1,14 @@
-name: components
-channels:
-  - conda-forge
-  - defaults
-dependencies:
-  - python=3.10
-  - pyyaml
-  - hydra-core=1.3.2
-  - pip
-  - pip:
-      - mlflow==2.8.1
-      - wandb==0.16.0
+name: components
+
+channels:
+  - conda-forge
+  - defaults
+
+dependencies:
+  - mlflow=2.1.1
+  - pyyaml=5.3.1
+  - hydra-core=1.0.6
+  - pip=20.3.3
+  - pip:
+      - wandb==0.13.9
+      - databricks_cli==0.8.7
\ No newline at end of file
diff --git a/config.yaml b/config.yaml
index a9f3a4b..80b478c 100644
--- a/config.yaml
+++ b/config.yaml
@@ -32,7 +32,7 @@ modeling:
     min_samples_leaf: 3
     # Here -1 means all available cores
     n_jobs: -1
-    criterion: mae
+    criterion: squared_error
     max_features: 0.5
     # DO not change the following
     oob_score: true
\ No newline at end of file
diff --git a/environment.yml b/environment.yml
index 2ab326c..3a049d1 100644
--- a/environment.yml
+++ b/environment.yml
@@ -4,6 +4,9 @@ channels:
   - defaults
 dependencies:
   - python=3.10
+  - numpy=1.23
+  - pyarrow=12.0.0
+  - scikit-learn=1.5.2
   - hydra-core=1.3.2
   - matplotlib=3.8.2
   - pandas=2.1.3
diff --git a/main.py b/main.py
index cc0c255..9451158 100644
--- a/main.py
+++ b/main.py
@@ -74,12 +74,18 @@ def go(config: DictConfig):
                 },
             )
 
-
         if "data_split" in active_steps:
-            ##################
-            # Implement here #
-            ##################
-            pass
+            _ = mlflow.run(
+                f"{config['main']['components_repository']}/train_val_test_split",
+                "main",
+                parameters={
+                    "input": "clean_sample.csv:latest",
+                    "test_size": config["modeling"]["test_size"],
+                    "random_seed": config["modeling"]["random_seed"],
+                    "stratify_by": config["modeling"]["stratify_by"]
+                },
+            )
+    
 
         if "train_random_forest" in active_steps:
 
@@ -94,19 +100,26 @@ def go(config: DictConfig):
                 os.path.join(hydra.utils.get_original_cwd(), "src", "train_random_forest"),
                 "main",
                 parameters={
-                    "input_artifact": "train_data.csv:latest",
-                    "output_artifact": "random_forest_model.pkl",
-                    "output_type": "random_forest_model",
-                    "output_description": "Trained Random Forest model",
-                    "rf_config": rf_config
+                    "trainval_artifact": "trainval_data.csv:latest",
+                    "val_size": config["modeling"]["val_size"],
+                    "random_seed": config["modeling"]["random_seed"],
+                    "stratify_by": config["modeling"]["stratify_by"],
+                    "rf_config": rf_config,
+                    "max_tfidf_features": config["modeling"]["max_tfidf_features"],
+                    "output_artifact": "random_forest_export"                  
                 }
             )
 
         if "test_regression_model" in active_steps:
-            ##################
-            # Implement here #
-            ##################
-            pass
+            _ = mlflow.run(
+                f"{config['main']['components_repository']}/test_regression_model",
+                "main",
+                parameters={
+                    "mlflow_model": "random_forest_export:prod",
+                    "test_dataset": "test_data.csv:latest"
+                }
+            )
+
 
 if __name__ == "__main__":
     go()
diff --git a/src/basic_cleaning/conda.yml b/src/basic_cleaning/conda.yml
index bbebb3d..f5c13b7 100644
--- a/src/basic_cleaning/conda.yml
+++ b/src/basic_cleaning/conda.yml
@@ -1,13 +1,14 @@
-name: basic_cleaning
-channels:
-  - conda-forge
-  - defaults
-dependencies:
-  - python=3.10
-  - pyyaml
-  - hydra-core=1.3.2
-  - pytest
-  - pip
-  - pip:
-      - mlflow==2.8.1
-      - wandb==0.16.0
\ No newline at end of file
+name: basic_cleaning
+
+channels:
+  - conda-forge
+  - defaults
+
+dependencies:
+  - mlflow=2.1.1
+  - pyyaml=5.3.1
+  - hydra-core=1.0.6
+  - pip=20.3.3
+  - pip:
+      - wandb==0.13.9
+      - databricks_cli==0.8.7 d
\ No newline at end of file
diff --git a/src/data_check/conda.yml b/src/data_check/conda.yml
index 4304836..8e8b3e7 100644
--- a/src/data_check/conda.yml
+++ b/src/data_check/conda.yml
@@ -1,13 +1,14 @@
-name: data_check
-channels:
-  - conda-forge
-  - defaults
-dependencies:
-  - python=3.10
-  - pyyaml
-  - hydra-core=1.3.2
-  - pytest
-  - pip
-  - pip:
-      - mlflow==2.8.1
-      - wandb==0.16.0
\ No newline at end of file
+name: data_check
+
+channels:
+  - conda-forge
+  - defaults
+
+dependencies:
+  - mlflow=2.1.1
+  - pyyaml=5.3.1
+  - hydra-core=1.0.6
+  - pip=20.3.3
+  - pip:
+      - wandb==0.13.9
+      - databricks_cli==0.8.7
\ No newline at end of file
diff --git a/src/eda/.ipynb_checkpoints/eda-checkpoint.ipynb b/src/eda/.ipynb_checkpoints/eda-checkpoint.ipynb
index 3c4dd3e..ef219b0 100644
--- a/src/eda/.ipynb_checkpoints/eda-checkpoint.ipynb
+++ b/src/eda/.ipynb_checkpoints/eda-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": null,
    "id": "1f72a955",
    "metadata": {
     "scrolled": true,
@@ -46,8 +46,7 @@
       "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas-profiling==3.6.2) (3.1.4)\n",
       "Collecting visions==0.7.5 (from visions[type_image_path]==0.7.5->pandas-profiling==3.6.2)\n",
       "  Using cached visions-0.7.5-py3-none-any.whl.metadata (6.3 kB)\n",
-      "Collecting numpy<1.24,>=1.16.0 (from pandas-profiling==3.6.2)\n",
-      "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
+      "Requirement already satisfied: numpy<1.24,>=1.16.0 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas-profiling==3.6.2) (1.23.5)\n",
       "Collecting htmlmin==0.1.12 (from pandas-profiling==3.6.2)\n",
       "  Using cached htmlmin-0.1.12-py3-none-any.whl\n",
       "Collecting phik<0.13,>=0.11.1 (from pandas-profiling==3.6.2)\n",
@@ -98,7 +97,6 @@
       "Using cached visions-0.7.5-py3-none-any.whl (102 kB)\n",
       "Using cached matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
       "Using cached multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
-      "Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
       "Using cached pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
       "Using cached phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (686 kB)\n",
       "Using cached pydantic-1.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
@@ -114,50 +112,15 @@
       "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
       "Using cached ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
       "Using cached pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
-      "Installing collected packages: htmlmin, urllib3, typeguard, tqdm, tangled-up-in-unicode, pydantic, numpy, networkx, multimethod, scipy, requests, PyWavelets, patsy, pandas, visions, statsmodels, matplotlib, imagehash, seaborn, phik, pandas-profiling\n",
+      "Installing collected packages: htmlmin, urllib3, typeguard, tqdm, tangled-up-in-unicode, scipy, PyWavelets, pydantic, patsy, networkx, multimethod, requests, pandas, matplotlib, imagehash, visions, statsmodels, seaborn, phik, pandas-profiling\n",
       "  Attempting uninstall: urllib3\n",
       "    Found existing installation: urllib3 2.2.2\n",
       "    Uninstalling urllib3-2.2.2:\n",
       "      Successfully uninstalled urllib3-2.2.2\n",
-      "  Attempting uninstall: numpy\n",
-      "    Found existing installation: numpy 1.26.4\n",
-      "    Uninstalling numpy-1.26.4:\n",
-      "      Successfully uninstalled numpy-1.26.4\n",
       "  Attempting uninstall: scipy\n",
       "    Found existing installation: scipy 1.14.1\n",
       "    Uninstalling scipy-1.14.1:\n",
-      "      Successfully uninstalled scipy-1.14.1\n",
-      "  Attempting uninstall: requests\n",
-      "    Found existing installation: requests 2.32.3\n",
-      "    Uninstalling requests-2.32.3:\n",
-      "      Successfully uninstalled requests-2.32.3\n",
-      "  Attempting uninstall: pandas\n",
-      "    Found existing installation: pandas 2.1.3\n",
-      "    Uninstalling pandas-2.1.3:\n",
-      "      Successfully uninstalled pandas-2.1.3\n",
-      "  Attempting uninstall: matplotlib\n",
-      "    Found existing installation: matplotlib 3.8.2\n",
-      "    Uninstalling matplotlib-3.8.2:\n",
-      "      Successfully uninstalled matplotlib-3.8.2\n",
-      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
-      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
-      "\u001b[0mSuccessfully installed PyWavelets-1.7.0 htmlmin-0.1.12 imagehash-4.3.1 matplotlib-3.6.3 multimethod-1.9.1 networkx-3.3 numpy-1.23.5 pandas-1.5.3 pandas-profiling-3.6.2 patsy-0.5.6 phik-0.12.4 pydantic-1.10.18 requests-2.28.2 scipy-1.9.3 seaborn-0.12.2 statsmodels-0.13.5 tangled-up-in-unicode-0.2.0 tqdm-4.64.1 typeguard-2.13.3 urllib3-1.26.20 visions-0.7.5\n",
-      "Collecting pandas==2.1.3\n",
-      "  Using cached pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
-      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (1.23.5)\n",
-      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (2.9.0)\n",
-      "Requirement already satisfied: pytz>=2020.1 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (2023.4)\n",
-      "Requirement already satisfied: tzdata>=2022.1 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (2024.1)\n",
-      "Requirement already satisfied: six>=1.5 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.1.3) (1.16.0)\n",
-      "Using cached pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
-      "Installing collected packages: pandas\n",
-      "  Attempting uninstall: pandas\n",
-      "    Found existing installation: pandas 1.5.3\n",
-      "    Uninstalling pandas-1.5.3:\n",
-      "      Successfully uninstalled pandas-1.5.3\n",
-      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
-      "pandas-profiling 3.6.2 requires pandas!=1.4.0,<1.6,>1.1, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
-      "\u001b[0mSuccessfully installed pandas-2.1.3\n"
+      "      Successfully uninstalled scipy-1.14.1\n"
      ]
     }
    ],
@@ -177,91 +140,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "id": "eed98c34",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkcline07\u001b[0m (\u001b[33mkcline07-western-governors-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
-     ]
-    },
-    {
-     "data": {
-      "text/html": [
-       "wandb version 0.18.0 is available!  To upgrade, please run:\n",
-       " $ pip install wandb --upgrade"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Tracking run with wandb version 0.16.0"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Run data is saved locally in <code>/home/kim/Project-Build-an-ML-Pipeline-Starter/src/eda/wandb/run-20240915_123243-18hy3wpz</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz' target=\"_blank\">distinctive-cloud-2</a></strong> to <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View project at <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View run at <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
+   "outputs": [],
    "source": [
     "import wandb\n",
     "import pandas as pd\n",
@@ -281,413 +163,30 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "id": "e7902159",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "<class 'pandas.core.frame.DataFrame'>\n",
-      "RangeIndex: 20000 entries, 0 to 19999\n",
-      "Data columns (total 16 columns):\n",
-      " #   Column                          Non-Null Count  Dtype  \n",
-      "---  ------                          --------------  -----  \n",
-      " 0   id                              20000 non-null  int64  \n",
-      " 1   name                            19993 non-null  object \n",
-      " 2   host_id                         20000 non-null  int64  \n",
-      " 3   host_name                       19992 non-null  object \n",
-      " 4   neighbourhood_group             20000 non-null  object \n",
-      " 5   neighbourhood                   20000 non-null  object \n",
-      " 6   latitude                        20000 non-null  float64\n",
-      " 7   longitude                       20000 non-null  float64\n",
-      " 8   room_type                       20000 non-null  object \n",
-      " 9   price                           20000 non-null  int64  \n",
-      " 10  minimum_nights                  20000 non-null  int64  \n",
-      " 11  number_of_reviews               20000 non-null  int64  \n",
-      " 12  last_review                     15877 non-null  object \n",
-      " 13  reviews_per_month               15877 non-null  float64\n",
-      " 14  calculated_host_listings_count  20000 non-null  int64  \n",
-      " 15  availability_365                20000 non-null  int64  \n",
-      "dtypes: float64(3), int64(7), object(6)\n",
-      "memory usage: 2.4+ MB\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.info()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": null,
    "id": "ef6f1457",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>id</th>\n",
-       "      <th>host_id</th>\n",
-       "      <th>latitude</th>\n",
-       "      <th>longitude</th>\n",
-       "      <th>price</th>\n",
-       "      <th>minimum_nights</th>\n",
-       "      <th>number_of_reviews</th>\n",
-       "      <th>reviews_per_month</th>\n",
-       "      <th>calculated_host_listings_count</th>\n",
-       "      <th>availability_365</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>count</th>\n",
-       "      <td>2.000000e+04</td>\n",
-       "      <td>2.000000e+04</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>15877.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>mean</th>\n",
-       "      <td>1.892380e+07</td>\n",
-       "      <td>6.746034e+07</td>\n",
-       "      <td>40.728455</td>\n",
-       "      <td>-73.952125</td>\n",
-       "      <td>153.269050</td>\n",
-       "      <td>6.992100</td>\n",
-       "      <td>23.274100</td>\n",
-       "      <td>1.377446</td>\n",
-       "      <td>6.955450</td>\n",
-       "      <td>112.901200</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>std</th>\n",
-       "      <td>1.101223e+07</td>\n",
-       "      <td>7.857936e+07</td>\n",
-       "      <td>0.054755</td>\n",
-       "      <td>0.046559</td>\n",
-       "      <td>243.325609</td>\n",
-       "      <td>21.645449</td>\n",
-       "      <td>44.927793</td>\n",
-       "      <td>1.683006</td>\n",
-       "      <td>32.433831</td>\n",
-       "      <td>131.762226</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>min</th>\n",
-       "      <td>2.539000e+03</td>\n",
-       "      <td>2.571000e+03</td>\n",
-       "      <td>40.508730</td>\n",
-       "      <td>-74.239140</td>\n",
-       "      <td>0.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "      <td>0.010000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>25%</th>\n",
-       "      <td>9.393540e+06</td>\n",
-       "      <td>7.853718e+06</td>\n",
-       "      <td>40.689420</td>\n",
-       "      <td>-73.983030</td>\n",
-       "      <td>69.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.190000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>50%</th>\n",
-       "      <td>1.952117e+07</td>\n",
-       "      <td>3.111431e+07</td>\n",
-       "      <td>40.722730</td>\n",
-       "      <td>-73.955640</td>\n",
-       "      <td>105.000000</td>\n",
-       "      <td>2.000000</td>\n",
-       "      <td>5.000000</td>\n",
-       "      <td>0.720000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>44.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>75%</th>\n",
-       "      <td>2.912936e+07</td>\n",
-       "      <td>1.068426e+08</td>\n",
-       "      <td>40.762990</td>\n",
-       "      <td>-73.936380</td>\n",
-       "      <td>175.000000</td>\n",
-       "      <td>5.000000</td>\n",
-       "      <td>23.000000</td>\n",
-       "      <td>2.010000</td>\n",
-       "      <td>2.000000</td>\n",
-       "      <td>229.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>max</th>\n",
-       "      <td>3.648561e+07</td>\n",
-       "      <td>2.742733e+08</td>\n",
-       "      <td>40.913060</td>\n",
-       "      <td>-73.717950</td>\n",
-       "      <td>10000.000000</td>\n",
-       "      <td>1250.000000</td>\n",
-       "      <td>607.000000</td>\n",
-       "      <td>27.950000</td>\n",
-       "      <td>327.000000</td>\n",
-       "      <td>365.000000</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "                 id       host_id      latitude     longitude         price  \\\n",
-       "count  2.000000e+04  2.000000e+04  20000.000000  20000.000000  20000.000000   \n",
-       "mean   1.892380e+07  6.746034e+07     40.728455    -73.952125    153.269050   \n",
-       "std    1.101223e+07  7.857936e+07      0.054755      0.046559    243.325609   \n",
-       "min    2.539000e+03  2.571000e+03     40.508730    -74.239140      0.000000   \n",
-       "25%    9.393540e+06  7.853718e+06     40.689420    -73.983030     69.000000   \n",
-       "50%    1.952117e+07  3.111431e+07     40.722730    -73.955640    105.000000   \n",
-       "75%    2.912936e+07  1.068426e+08     40.762990    -73.936380    175.000000   \n",
-       "max    3.648561e+07  2.742733e+08     40.913060    -73.717950  10000.000000   \n",
-       "\n",
-       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
-       "count    20000.000000       20000.000000       15877.000000   \n",
-       "mean         6.992100          23.274100           1.377446   \n",
-       "std         21.645449          44.927793           1.683006   \n",
-       "min          1.000000           0.000000           0.010000   \n",
-       "25%          1.000000           1.000000           0.190000   \n",
-       "50%          2.000000           5.000000           0.720000   \n",
-       "75%          5.000000          23.000000           2.010000   \n",
-       "max       1250.000000         607.000000          27.950000   \n",
-       "\n",
-       "       calculated_host_listings_count  availability_365  \n",
-       "count                    20000.000000      20000.000000  \n",
-       "mean                         6.955450        112.901200  \n",
-       "std                         32.433831        131.762226  \n",
-       "min                          1.000000          0.000000  \n",
-       "25%                          1.000000          0.000000  \n",
-       "50%                          1.000000         44.000000  \n",
-       "75%                          2.000000        229.000000  \n",
-       "max                        327.000000        365.000000  "
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.describe()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "id": "13548f59",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>id</th>\n",
-       "      <th>name</th>\n",
-       "      <th>host_id</th>\n",
-       "      <th>host_name</th>\n",
-       "      <th>neighbourhood_group</th>\n",
-       "      <th>neighbourhood</th>\n",
-       "      <th>latitude</th>\n",
-       "      <th>longitude</th>\n",
-       "      <th>room_type</th>\n",
-       "      <th>price</th>\n",
-       "      <th>minimum_nights</th>\n",
-       "      <th>number_of_reviews</th>\n",
-       "      <th>last_review</th>\n",
-       "      <th>reviews_per_month</th>\n",
-       "      <th>calculated_host_listings_count</th>\n",
-       "      <th>availability_365</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>0</th>\n",
-       "      <td>9138664</td>\n",
-       "      <td>Private Lg Room 15 min to Manhattan</td>\n",
-       "      <td>47594947</td>\n",
-       "      <td>Iris</td>\n",
-       "      <td>Queens</td>\n",
-       "      <td>Sunnyside</td>\n",
-       "      <td>40.74271</td>\n",
-       "      <td>-73.92493</td>\n",
-       "      <td>Private room</td>\n",
-       "      <td>74</td>\n",
-       "      <td>2</td>\n",
-       "      <td>6</td>\n",
-       "      <td>2019-05-26</td>\n",
-       "      <td>0.13</td>\n",
-       "      <td>1</td>\n",
-       "      <td>5</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>31444015</td>\n",
-       "      <td>TIME SQUARE CHARMING ONE BED IN HELL'S KITCHEN...</td>\n",
-       "      <td>8523790</td>\n",
-       "      <td>Johlex</td>\n",
-       "      <td>Manhattan</td>\n",
-       "      <td>Hell's Kitchen</td>\n",
-       "      <td>40.76682</td>\n",
-       "      <td>-73.98878</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>170</td>\n",
-       "      <td>3</td>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>1</td>\n",
-       "      <td>188</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>2</th>\n",
-       "      <td>8741020</td>\n",
-       "      <td>Voted #1 Location Quintessential 1BR W Village...</td>\n",
-       "      <td>45854238</td>\n",
-       "      <td>John</td>\n",
-       "      <td>Manhattan</td>\n",
-       "      <td>West Village</td>\n",
-       "      <td>40.73631</td>\n",
-       "      <td>-74.00611</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>245</td>\n",
-       "      <td>3</td>\n",
-       "      <td>51</td>\n",
-       "      <td>2018-09-19</td>\n",
-       "      <td>1.12</td>\n",
-       "      <td>1</td>\n",
-       "      <td>0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>3</th>\n",
-       "      <td>34602077</td>\n",
-       "      <td>Spacious 1 bedroom apartment 15min from Manhattan</td>\n",
-       "      <td>261055465</td>\n",
-       "      <td>Regan</td>\n",
-       "      <td>Queens</td>\n",
-       "      <td>Astoria</td>\n",
-       "      <td>40.76424</td>\n",
-       "      <td>-73.92351</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>125</td>\n",
-       "      <td>3</td>\n",
-       "      <td>1</td>\n",
-       "      <td>2019-05-24</td>\n",
-       "      <td>0.65</td>\n",
-       "      <td>1</td>\n",
-       "      <td>13</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>4</th>\n",
-       "      <td>23203149</td>\n",
-       "      <td>Big beautiful bedroom in huge Bushwick apartment</td>\n",
-       "      <td>143460</td>\n",
-       "      <td>Megan</td>\n",
-       "      <td>Brooklyn</td>\n",
-       "      <td>Bushwick</td>\n",
-       "      <td>40.69839</td>\n",
-       "      <td>-73.92044</td>\n",
-       "      <td>Private room</td>\n",
-       "      <td>65</td>\n",
-       "      <td>2</td>\n",
-       "      <td>8</td>\n",
-       "      <td>2019-06-23</td>\n",
-       "      <td>0.52</td>\n",
-       "      <td>2</td>\n",
-       "      <td>8</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "         id                                               name    host_id  \\\n",
-       "0   9138664                Private Lg Room 15 min to Manhattan   47594947   \n",
-       "1  31444015  TIME SQUARE CHARMING ONE BED IN HELL'S KITCHEN...    8523790   \n",
-       "2   8741020  Voted #1 Location Quintessential 1BR W Village...   45854238   \n",
-       "3  34602077  Spacious 1 bedroom apartment 15min from Manhattan  261055465   \n",
-       "4  23203149   Big beautiful bedroom in huge Bushwick apartment     143460   \n",
-       "\n",
-       "  host_name neighbourhood_group   neighbourhood  latitude  longitude  \\\n",
-       "0      Iris              Queens       Sunnyside  40.74271  -73.92493   \n",
-       "1    Johlex           Manhattan  Hell's Kitchen  40.76682  -73.98878   \n",
-       "2      John           Manhattan    West Village  40.73631  -74.00611   \n",
-       "3     Regan              Queens         Astoria  40.76424  -73.92351   \n",
-       "4     Megan            Brooklyn        Bushwick  40.69839  -73.92044   \n",
-       "\n",
-       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
-       "0     Private room     74               2                  6  2019-05-26   \n",
-       "1  Entire home/apt    170               3                  0         NaN   \n",
-       "2  Entire home/apt    245               3                 51  2018-09-19   \n",
-       "3  Entire home/apt    125               3                  1  2019-05-24   \n",
-       "4     Private room     65               2                  8  2019-06-23   \n",
-       "\n",
-       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
-       "0               0.13                               1                 5  \n",
-       "1                NaN                               1               188  \n",
-       "2               1.12                               1                 0  \n",
-       "3               0.65                               1                13  \n",
-       "4               0.52                               2                 8  "
-      ]
-     },
-     "execution_count": 5,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.head()"
    ]
@@ -712,7 +211,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": null,
    "id": "4d685317",
    "metadata": {},
    "outputs": [],
@@ -744,40 +243,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": null,
    "id": "b83b4970",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "<class 'pandas.core.frame.DataFrame'>\n",
-      "Index: 19001 entries, 0 to 19999\n",
-      "Data columns (total 16 columns):\n",
-      " #   Column                          Non-Null Count  Dtype         \n",
-      "---  ------                          --------------  -----         \n",
-      " 0   id                              19001 non-null  int64         \n",
-      " 1   name                            18994 non-null  object        \n",
-      " 2   host_id                         19001 non-null  int64         \n",
-      " 3   host_name                       18993 non-null  object        \n",
-      " 4   neighbourhood_group             19001 non-null  object        \n",
-      " 5   neighbourhood                   19001 non-null  object        \n",
-      " 6   latitude                        19001 non-null  float64       \n",
-      " 7   longitude                       19001 non-null  float64       \n",
-      " 8   room_type                       19001 non-null  object        \n",
-      " 9   price                           19001 non-null  int64         \n",
-      " 10  minimum_nights                  19001 non-null  int64         \n",
-      " 11  number_of_reviews               19001 non-null  int64         \n",
-      " 12  last_review                     15243 non-null  datetime64[ns]\n",
-      " 13  reviews_per_month               15243 non-null  float64       \n",
-      " 14  calculated_host_listings_count  19001 non-null  int64         \n",
-      " 15  availability_365                19001 non-null  int64         \n",
-      "dtypes: datetime64[ns](1), float64(3), int64(7), object(5)\n",
-      "memory usage: 2.5+ MB\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.info()"
    ]
@@ -792,35 +261,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": null,
    "id": "48b38586",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       " View run <strong style=\"color:#cdcd00\">distinctive-cloud-2</strong> at: <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz</a><br/> View job at <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQ1NjQ4NjY0NA==/version_details/v0' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQ1NjQ4NjY0NA==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Find logs at: <code>./wandb/run-20240915_123243-18hy3wpz/logs</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
+   "outputs": [],
    "source": [
     "run.finish()"
    ]
diff --git a/src/eda/conda.yml b/src/eda/conda.yml
index 7be3652..b01c948 100644
--- a/src/eda/conda.yml
+++ b/src/eda/conda.yml
@@ -1,13 +1,14 @@
-name: eda
-channels:
-  - conda-forge
-  - defaults
-dependencies:
-  - python=3.10
-  - pyyaml
-  - hydra-core=1.3.2
-  - pytest
-  - pip
-  - pip:
-      - mlflow==2.8.1
-      - wandb==0.16.0
\ No newline at end of file
+name: eda
+
+channels:
+  - conda-forge
+  - defaults
+
+dependencies:
+  - mlflow=2.1.1
+  - pyyaml=5.3.1
+  - hydra-core=1.0.6
+  - pip=20.3.3
+  - pip:
+      - wandb==0.13.9
+      - databricks_cli==0.8.7
\ No newline at end of file
diff --git a/src/eda/eda.ipynb b/src/eda/eda.ipynb
index 3c4dd3e..ef219b0 100644
--- a/src/eda/eda.ipynb
+++ b/src/eda/eda.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": null,
    "id": "1f72a955",
    "metadata": {
     "scrolled": true,
@@ -46,8 +46,7 @@
       "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas-profiling==3.6.2) (3.1.4)\n",
       "Collecting visions==0.7.5 (from visions[type_image_path]==0.7.5->pandas-profiling==3.6.2)\n",
       "  Using cached visions-0.7.5-py3-none-any.whl.metadata (6.3 kB)\n",
-      "Collecting numpy<1.24,>=1.16.0 (from pandas-profiling==3.6.2)\n",
-      "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
+      "Requirement already satisfied: numpy<1.24,>=1.16.0 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas-profiling==3.6.2) (1.23.5)\n",
       "Collecting htmlmin==0.1.12 (from pandas-profiling==3.6.2)\n",
       "  Using cached htmlmin-0.1.12-py3-none-any.whl\n",
       "Collecting phik<0.13,>=0.11.1 (from pandas-profiling==3.6.2)\n",
@@ -98,7 +97,6 @@
       "Using cached visions-0.7.5-py3-none-any.whl (102 kB)\n",
       "Using cached matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
       "Using cached multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
-      "Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
       "Using cached pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
       "Using cached phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (686 kB)\n",
       "Using cached pydantic-1.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
@@ -114,50 +112,15 @@
       "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
       "Using cached ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
       "Using cached pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
-      "Installing collected packages: htmlmin, urllib3, typeguard, tqdm, tangled-up-in-unicode, pydantic, numpy, networkx, multimethod, scipy, requests, PyWavelets, patsy, pandas, visions, statsmodels, matplotlib, imagehash, seaborn, phik, pandas-profiling\n",
+      "Installing collected packages: htmlmin, urllib3, typeguard, tqdm, tangled-up-in-unicode, scipy, PyWavelets, pydantic, patsy, networkx, multimethod, requests, pandas, matplotlib, imagehash, visions, statsmodels, seaborn, phik, pandas-profiling\n",
       "  Attempting uninstall: urllib3\n",
       "    Found existing installation: urllib3 2.2.2\n",
       "    Uninstalling urllib3-2.2.2:\n",
       "      Successfully uninstalled urllib3-2.2.2\n",
-      "  Attempting uninstall: numpy\n",
-      "    Found existing installation: numpy 1.26.4\n",
-      "    Uninstalling numpy-1.26.4:\n",
-      "      Successfully uninstalled numpy-1.26.4\n",
       "  Attempting uninstall: scipy\n",
       "    Found existing installation: scipy 1.14.1\n",
       "    Uninstalling scipy-1.14.1:\n",
-      "      Successfully uninstalled scipy-1.14.1\n",
-      "  Attempting uninstall: requests\n",
-      "    Found existing installation: requests 2.32.3\n",
-      "    Uninstalling requests-2.32.3:\n",
-      "      Successfully uninstalled requests-2.32.3\n",
-      "  Attempting uninstall: pandas\n",
-      "    Found existing installation: pandas 2.1.3\n",
-      "    Uninstalling pandas-2.1.3:\n",
-      "      Successfully uninstalled pandas-2.1.3\n",
-      "  Attempting uninstall: matplotlib\n",
-      "    Found existing installation: matplotlib 3.8.2\n",
-      "    Uninstalling matplotlib-3.8.2:\n",
-      "      Successfully uninstalled matplotlib-3.8.2\n",
-      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
-      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
-      "\u001b[0mSuccessfully installed PyWavelets-1.7.0 htmlmin-0.1.12 imagehash-4.3.1 matplotlib-3.6.3 multimethod-1.9.1 networkx-3.3 numpy-1.23.5 pandas-1.5.3 pandas-profiling-3.6.2 patsy-0.5.6 phik-0.12.4 pydantic-1.10.18 requests-2.28.2 scipy-1.9.3 seaborn-0.12.2 statsmodels-0.13.5 tangled-up-in-unicode-0.2.0 tqdm-4.64.1 typeguard-2.13.3 urllib3-1.26.20 visions-0.7.5\n",
-      "Collecting pandas==2.1.3\n",
-      "  Using cached pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
-      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (1.23.5)\n",
-      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (2.9.0)\n",
-      "Requirement already satisfied: pytz>=2020.1 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (2023.4)\n",
-      "Requirement already satisfied: tzdata>=2022.1 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from pandas==2.1.3) (2024.1)\n",
-      "Requirement already satisfied: six>=1.5 in /home/kim/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.1.3) (1.16.0)\n",
-      "Using cached pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
-      "Installing collected packages: pandas\n",
-      "  Attempting uninstall: pandas\n",
-      "    Found existing installation: pandas 1.5.3\n",
-      "    Uninstalling pandas-1.5.3:\n",
-      "      Successfully uninstalled pandas-1.5.3\n",
-      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
-      "pandas-profiling 3.6.2 requires pandas!=1.4.0,<1.6,>1.1, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
-      "\u001b[0mSuccessfully installed pandas-2.1.3\n"
+      "      Successfully uninstalled scipy-1.14.1\n"
      ]
     }
    ],
@@ -177,91 +140,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "id": "eed98c34",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkcline07\u001b[0m (\u001b[33mkcline07-western-governors-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
-     ]
-    },
-    {
-     "data": {
-      "text/html": [
-       "wandb version 0.18.0 is available!  To upgrade, please run:\n",
-       " $ pip install wandb --upgrade"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Tracking run with wandb version 0.16.0"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Run data is saved locally in <code>/home/kim/Project-Build-an-ML-Pipeline-Starter/src/eda/wandb/run-20240915_123243-18hy3wpz</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz' target=\"_blank\">distinctive-cloud-2</a></strong> to <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View project at <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       " View run at <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz</a>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
+   "outputs": [],
    "source": [
     "import wandb\n",
     "import pandas as pd\n",
@@ -281,413 +163,30 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "id": "e7902159",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "<class 'pandas.core.frame.DataFrame'>\n",
-      "RangeIndex: 20000 entries, 0 to 19999\n",
-      "Data columns (total 16 columns):\n",
-      " #   Column                          Non-Null Count  Dtype  \n",
-      "---  ------                          --------------  -----  \n",
-      " 0   id                              20000 non-null  int64  \n",
-      " 1   name                            19993 non-null  object \n",
-      " 2   host_id                         20000 non-null  int64  \n",
-      " 3   host_name                       19992 non-null  object \n",
-      " 4   neighbourhood_group             20000 non-null  object \n",
-      " 5   neighbourhood                   20000 non-null  object \n",
-      " 6   latitude                        20000 non-null  float64\n",
-      " 7   longitude                       20000 non-null  float64\n",
-      " 8   room_type                       20000 non-null  object \n",
-      " 9   price                           20000 non-null  int64  \n",
-      " 10  minimum_nights                  20000 non-null  int64  \n",
-      " 11  number_of_reviews               20000 non-null  int64  \n",
-      " 12  last_review                     15877 non-null  object \n",
-      " 13  reviews_per_month               15877 non-null  float64\n",
-      " 14  calculated_host_listings_count  20000 non-null  int64  \n",
-      " 15  availability_365                20000 non-null  int64  \n",
-      "dtypes: float64(3), int64(7), object(6)\n",
-      "memory usage: 2.4+ MB\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.info()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": null,
    "id": "ef6f1457",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>id</th>\n",
-       "      <th>host_id</th>\n",
-       "      <th>latitude</th>\n",
-       "      <th>longitude</th>\n",
-       "      <th>price</th>\n",
-       "      <th>minimum_nights</th>\n",
-       "      <th>number_of_reviews</th>\n",
-       "      <th>reviews_per_month</th>\n",
-       "      <th>calculated_host_listings_count</th>\n",
-       "      <th>availability_365</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>count</th>\n",
-       "      <td>2.000000e+04</td>\n",
-       "      <td>2.000000e+04</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>15877.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "      <td>20000.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>mean</th>\n",
-       "      <td>1.892380e+07</td>\n",
-       "      <td>6.746034e+07</td>\n",
-       "      <td>40.728455</td>\n",
-       "      <td>-73.952125</td>\n",
-       "      <td>153.269050</td>\n",
-       "      <td>6.992100</td>\n",
-       "      <td>23.274100</td>\n",
-       "      <td>1.377446</td>\n",
-       "      <td>6.955450</td>\n",
-       "      <td>112.901200</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>std</th>\n",
-       "      <td>1.101223e+07</td>\n",
-       "      <td>7.857936e+07</td>\n",
-       "      <td>0.054755</td>\n",
-       "      <td>0.046559</td>\n",
-       "      <td>243.325609</td>\n",
-       "      <td>21.645449</td>\n",
-       "      <td>44.927793</td>\n",
-       "      <td>1.683006</td>\n",
-       "      <td>32.433831</td>\n",
-       "      <td>131.762226</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>min</th>\n",
-       "      <td>2.539000e+03</td>\n",
-       "      <td>2.571000e+03</td>\n",
-       "      <td>40.508730</td>\n",
-       "      <td>-74.239140</td>\n",
-       "      <td>0.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "      <td>0.010000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>25%</th>\n",
-       "      <td>9.393540e+06</td>\n",
-       "      <td>7.853718e+06</td>\n",
-       "      <td>40.689420</td>\n",
-       "      <td>-73.983030</td>\n",
-       "      <td>69.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.190000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>0.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>50%</th>\n",
-       "      <td>1.952117e+07</td>\n",
-       "      <td>3.111431e+07</td>\n",
-       "      <td>40.722730</td>\n",
-       "      <td>-73.955640</td>\n",
-       "      <td>105.000000</td>\n",
-       "      <td>2.000000</td>\n",
-       "      <td>5.000000</td>\n",
-       "      <td>0.720000</td>\n",
-       "      <td>1.000000</td>\n",
-       "      <td>44.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>75%</th>\n",
-       "      <td>2.912936e+07</td>\n",
-       "      <td>1.068426e+08</td>\n",
-       "      <td>40.762990</td>\n",
-       "      <td>-73.936380</td>\n",
-       "      <td>175.000000</td>\n",
-       "      <td>5.000000</td>\n",
-       "      <td>23.000000</td>\n",
-       "      <td>2.010000</td>\n",
-       "      <td>2.000000</td>\n",
-       "      <td>229.000000</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>max</th>\n",
-       "      <td>3.648561e+07</td>\n",
-       "      <td>2.742733e+08</td>\n",
-       "      <td>40.913060</td>\n",
-       "      <td>-73.717950</td>\n",
-       "      <td>10000.000000</td>\n",
-       "      <td>1250.000000</td>\n",
-       "      <td>607.000000</td>\n",
-       "      <td>27.950000</td>\n",
-       "      <td>327.000000</td>\n",
-       "      <td>365.000000</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "                 id       host_id      latitude     longitude         price  \\\n",
-       "count  2.000000e+04  2.000000e+04  20000.000000  20000.000000  20000.000000   \n",
-       "mean   1.892380e+07  6.746034e+07     40.728455    -73.952125    153.269050   \n",
-       "std    1.101223e+07  7.857936e+07      0.054755      0.046559    243.325609   \n",
-       "min    2.539000e+03  2.571000e+03     40.508730    -74.239140      0.000000   \n",
-       "25%    9.393540e+06  7.853718e+06     40.689420    -73.983030     69.000000   \n",
-       "50%    1.952117e+07  3.111431e+07     40.722730    -73.955640    105.000000   \n",
-       "75%    2.912936e+07  1.068426e+08     40.762990    -73.936380    175.000000   \n",
-       "max    3.648561e+07  2.742733e+08     40.913060    -73.717950  10000.000000   \n",
-       "\n",
-       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
-       "count    20000.000000       20000.000000       15877.000000   \n",
-       "mean         6.992100          23.274100           1.377446   \n",
-       "std         21.645449          44.927793           1.683006   \n",
-       "min          1.000000           0.000000           0.010000   \n",
-       "25%          1.000000           1.000000           0.190000   \n",
-       "50%          2.000000           5.000000           0.720000   \n",
-       "75%          5.000000          23.000000           2.010000   \n",
-       "max       1250.000000         607.000000          27.950000   \n",
-       "\n",
-       "       calculated_host_listings_count  availability_365  \n",
-       "count                    20000.000000      20000.000000  \n",
-       "mean                         6.955450        112.901200  \n",
-       "std                         32.433831        131.762226  \n",
-       "min                          1.000000          0.000000  \n",
-       "25%                          1.000000          0.000000  \n",
-       "50%                          1.000000         44.000000  \n",
-       "75%                          2.000000        229.000000  \n",
-       "max                        327.000000        365.000000  "
-      ]
-     },
-     "execution_count": 4,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.describe()"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": null,
    "id": "13548f59",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>id</th>\n",
-       "      <th>name</th>\n",
-       "      <th>host_id</th>\n",
-       "      <th>host_name</th>\n",
-       "      <th>neighbourhood_group</th>\n",
-       "      <th>neighbourhood</th>\n",
-       "      <th>latitude</th>\n",
-       "      <th>longitude</th>\n",
-       "      <th>room_type</th>\n",
-       "      <th>price</th>\n",
-       "      <th>minimum_nights</th>\n",
-       "      <th>number_of_reviews</th>\n",
-       "      <th>last_review</th>\n",
-       "      <th>reviews_per_month</th>\n",
-       "      <th>calculated_host_listings_count</th>\n",
-       "      <th>availability_365</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>0</th>\n",
-       "      <td>9138664</td>\n",
-       "      <td>Private Lg Room 15 min to Manhattan</td>\n",
-       "      <td>47594947</td>\n",
-       "      <td>Iris</td>\n",
-       "      <td>Queens</td>\n",
-       "      <td>Sunnyside</td>\n",
-       "      <td>40.74271</td>\n",
-       "      <td>-73.92493</td>\n",
-       "      <td>Private room</td>\n",
-       "      <td>74</td>\n",
-       "      <td>2</td>\n",
-       "      <td>6</td>\n",
-       "      <td>2019-05-26</td>\n",
-       "      <td>0.13</td>\n",
-       "      <td>1</td>\n",
-       "      <td>5</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>31444015</td>\n",
-       "      <td>TIME SQUARE CHARMING ONE BED IN HELL'S KITCHEN...</td>\n",
-       "      <td>8523790</td>\n",
-       "      <td>Johlex</td>\n",
-       "      <td>Manhattan</td>\n",
-       "      <td>Hell's Kitchen</td>\n",
-       "      <td>40.76682</td>\n",
-       "      <td>-73.98878</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>170</td>\n",
-       "      <td>3</td>\n",
-       "      <td>0</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>NaN</td>\n",
-       "      <td>1</td>\n",
-       "      <td>188</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>2</th>\n",
-       "      <td>8741020</td>\n",
-       "      <td>Voted #1 Location Quintessential 1BR W Village...</td>\n",
-       "      <td>45854238</td>\n",
-       "      <td>John</td>\n",
-       "      <td>Manhattan</td>\n",
-       "      <td>West Village</td>\n",
-       "      <td>40.73631</td>\n",
-       "      <td>-74.00611</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>245</td>\n",
-       "      <td>3</td>\n",
-       "      <td>51</td>\n",
-       "      <td>2018-09-19</td>\n",
-       "      <td>1.12</td>\n",
-       "      <td>1</td>\n",
-       "      <td>0</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>3</th>\n",
-       "      <td>34602077</td>\n",
-       "      <td>Spacious 1 bedroom apartment 15min from Manhattan</td>\n",
-       "      <td>261055465</td>\n",
-       "      <td>Regan</td>\n",
-       "      <td>Queens</td>\n",
-       "      <td>Astoria</td>\n",
-       "      <td>40.76424</td>\n",
-       "      <td>-73.92351</td>\n",
-       "      <td>Entire home/apt</td>\n",
-       "      <td>125</td>\n",
-       "      <td>3</td>\n",
-       "      <td>1</td>\n",
-       "      <td>2019-05-24</td>\n",
-       "      <td>0.65</td>\n",
-       "      <td>1</td>\n",
-       "      <td>13</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>4</th>\n",
-       "      <td>23203149</td>\n",
-       "      <td>Big beautiful bedroom in huge Bushwick apartment</td>\n",
-       "      <td>143460</td>\n",
-       "      <td>Megan</td>\n",
-       "      <td>Brooklyn</td>\n",
-       "      <td>Bushwick</td>\n",
-       "      <td>40.69839</td>\n",
-       "      <td>-73.92044</td>\n",
-       "      <td>Private room</td>\n",
-       "      <td>65</td>\n",
-       "      <td>2</td>\n",
-       "      <td>8</td>\n",
-       "      <td>2019-06-23</td>\n",
-       "      <td>0.52</td>\n",
-       "      <td>2</td>\n",
-       "      <td>8</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "         id                                               name    host_id  \\\n",
-       "0   9138664                Private Lg Room 15 min to Manhattan   47594947   \n",
-       "1  31444015  TIME SQUARE CHARMING ONE BED IN HELL'S KITCHEN...    8523790   \n",
-       "2   8741020  Voted #1 Location Quintessential 1BR W Village...   45854238   \n",
-       "3  34602077  Spacious 1 bedroom apartment 15min from Manhattan  261055465   \n",
-       "4  23203149   Big beautiful bedroom in huge Bushwick apartment     143460   \n",
-       "\n",
-       "  host_name neighbourhood_group   neighbourhood  latitude  longitude  \\\n",
-       "0      Iris              Queens       Sunnyside  40.74271  -73.92493   \n",
-       "1    Johlex           Manhattan  Hell's Kitchen  40.76682  -73.98878   \n",
-       "2      John           Manhattan    West Village  40.73631  -74.00611   \n",
-       "3     Regan              Queens         Astoria  40.76424  -73.92351   \n",
-       "4     Megan            Brooklyn        Bushwick  40.69839  -73.92044   \n",
-       "\n",
-       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
-       "0     Private room     74               2                  6  2019-05-26   \n",
-       "1  Entire home/apt    170               3                  0         NaN   \n",
-       "2  Entire home/apt    245               3                 51  2018-09-19   \n",
-       "3  Entire home/apt    125               3                  1  2019-05-24   \n",
-       "4     Private room     65               2                  8  2019-06-23   \n",
-       "\n",
-       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
-       "0               0.13                               1                 5  \n",
-       "1                NaN                               1               188  \n",
-       "2               1.12                               1                 0  \n",
-       "3               0.65                               1                13  \n",
-       "4               0.52                               2                 8  "
-      ]
-     },
-     "execution_count": 5,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.head()"
    ]
@@ -712,7 +211,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": null,
    "id": "4d685317",
    "metadata": {},
    "outputs": [],
@@ -744,40 +243,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": null,
    "id": "b83b4970",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "<class 'pandas.core.frame.DataFrame'>\n",
-      "Index: 19001 entries, 0 to 19999\n",
-      "Data columns (total 16 columns):\n",
-      " #   Column                          Non-Null Count  Dtype         \n",
-      "---  ------                          --------------  -----         \n",
-      " 0   id                              19001 non-null  int64         \n",
-      " 1   name                            18994 non-null  object        \n",
-      " 2   host_id                         19001 non-null  int64         \n",
-      " 3   host_name                       18993 non-null  object        \n",
-      " 4   neighbourhood_group             19001 non-null  object        \n",
-      " 5   neighbourhood                   19001 non-null  object        \n",
-      " 6   latitude                        19001 non-null  float64       \n",
-      " 7   longitude                       19001 non-null  float64       \n",
-      " 8   room_type                       19001 non-null  object        \n",
-      " 9   price                           19001 non-null  int64         \n",
-      " 10  minimum_nights                  19001 non-null  int64         \n",
-      " 11  number_of_reviews               19001 non-null  int64         \n",
-      " 12  last_review                     15243 non-null  datetime64[ns]\n",
-      " 13  reviews_per_month               15243 non-null  float64       \n",
-      " 14  calculated_host_listings_count  19001 non-null  int64         \n",
-      " 15  availability_365                19001 non-null  int64         \n",
-      "dtypes: datetime64[ns](1), float64(3), int64(7), object(5)\n",
-      "memory usage: 2.5+ MB\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "df.info()"
    ]
@@ -792,35 +261,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": null,
    "id": "48b38586",
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       " View run <strong style=\"color:#cdcd00\">distinctive-cloud-2</strong> at: <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/runs/18hy3wpz</a><br/> View job at <a href='https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQ1NjQ4NjY0NA==/version_details/v0' target=\"_blank\">https://wandb.ai/kcline07-western-governors-university/nyc_airbnb/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQ1NjQ4NjY0NA==/version_details/v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/html": [
-       "Find logs at: <code>./wandb/run-20240915_123243-18hy3wpz/logs</code>"
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    }
-   ],
+   "outputs": [],
    "source": [
     "run.finish()"
    ]
diff --git a/src/eda/wandb/debug-internal.log b/src/eda/wandb/debug-internal.log
index 4577db3..6b94d33 120000
--- a/src/eda/wandb/debug-internal.log
+++ b/src/eda/wandb/debug-internal.log
@@ -1 +1 @@
-run-20240915_123243-18hy3wpz/logs/debug-internal.log
\ No newline at end of file
+run-20240915_204457-b8gusz3w/logs/debug-internal.log
\ No newline at end of file
diff --git a/src/eda/wandb/debug.log b/src/eda/wandb/debug.log
index d06ddee..34c3556 120000
--- a/src/eda/wandb/debug.log
+++ b/src/eda/wandb/debug.log
@@ -1 +1 @@
-run-20240915_123243-18hy3wpz/logs/debug.log
\ No newline at end of file
+run-20240915_204457-b8gusz3w/logs/debug.log
\ No newline at end of file
diff --git a/src/eda/wandb/latest-run b/src/eda/wandb/latest-run
index dcb1fee..6110147 120000
--- a/src/eda/wandb/latest-run
+++ b/src/eda/wandb/latest-run
@@ -1 +1 @@
-run-20240915_123243-18hy3wpz
\ No newline at end of file
+run-20240915_204457-b8gusz3w
\ No newline at end of file
diff --git a/src/train_random_forest/.ipynb_checkpoints/conda-checkpoint.yml b/src/train_random_forest/.ipynb_checkpoints/conda-checkpoint.yml
index 7a78e37..d0d504e 100644
--- a/src/train_random_forest/.ipynb_checkpoints/conda-checkpoint.yml
+++ b/src/train_random_forest/.ipynb_checkpoints/conda-checkpoint.yml
@@ -1,14 +1,14 @@
-name: basic_cleaning
-channels:
-  - conda-forge
-  - defaults
-dependencies:
-  - python=3.10
-  - hydra-core=1.3.2
-  - matplotlib=3.8.2
-  - pandas=2.1.3
-  - pip=23.3.1
-  - scikit-learn=1.3.2
-  - pip:
-      - mlflow==2.8.1
-      - wandb==0.16.0
+name: basic_cleaning
+
+channels:
+  - conda-forge
+  - defaults
+
+dependencies:
+  - mlflow=2.1.1
+  - pyyaml=5.3.1
+  - hydra-core=1.0.6
+  - pip=20.3.3
+  - pip:
+      - wandb==0.13.9
+      - databricks_cli==0.8.7
\ No newline at end of file
diff --git a/src/train_random_forest/conda.yml b/src/train_random_forest/conda.yml
index bbebb3d..d0d504e 100644
--- a/src/train_random_forest/conda.yml
+++ b/src/train_random_forest/conda.yml
@@ -1,13 +1,14 @@
-name: basic_cleaning
-channels:
-  - conda-forge
-  - defaults
-dependencies:
-  - python=3.10
-  - pyyaml
-  - hydra-core=1.3.2
-  - pytest
-  - pip
-  - pip:
-      - mlflow==2.8.1
-      - wandb==0.16.0
\ No newline at end of file
+name: basic_cleaning
+
+channels:
+  - conda-forge
+  - defaults
+
+dependencies:
+  - mlflow=2.1.1
+  - pyyaml=5.3.1
+  - hydra-core=1.0.6
+  - pip=20.3.3
+  - pip:
+      - wandb==0.13.9
+      - databricks_cli==0.8.7
\ No newline at end of file
diff --git a/src/train_random_forest/run.py b/src/train_random_forest/run.py
index 1d0781d..37de2e0 100644
--- a/src/train_random_forest/run.py
+++ b/src/train_random_forest/run.py
@@ -1,293 +1,298 @@
-#!/usr/bin/env python
-"""
-This script trains a Random Forest
-"""
-import argparse
-import logging
-import os
-import shutil
-import matplotlib.pyplot as plt
-
-import mlflow
-import json
-
-import pandas as pd
-import numpy as np
-from sklearn.compose import ColumnTransformer
-from sklearn.feature_extraction.text import TfidfVectorizer
-from sklearn.impute import SimpleImputer
-from sklearn.model_selection import train_test_split
-from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer
-
-import wandb
-from sklearn.ensemble import RandomForestRegressor
-from sklearn.metrics import mean_absolute_error
-from sklearn.pipeline import Pipeline, make_pipeline
-
-
-def delta_date_feature(dates):
-    """
-    Given a 2d array containing dates (in any format recognized by pd.to_datetime), it returns the delta in days
-    between each date and the most recent date in its column
-    """
-    date_sanitized = pd.DataFrame(dates).apply(pd.to_datetime)
-    return date_sanitized.apply(lambda d: (d.max() -d).dt.days, axis=0).to_numpy()
-
-
-logging.basicConfig(level=logging.INFO, format="%(asctime)-15s %(message)s")
-logger = logging.getLogger()
-
-
-def go(args):
-
-    run = wandb.init(job_type="train_random_forest")
-    run.config.update(args)
-
-    # Get the Random Forest configuration and update W&B
-    with open(args.rf_config) as fp:
-        rf_config = json.load(fp)
-    run.config.update(rf_config)
-
-    # Fix the random seed for the Random Forest, so we get reproducible results
-    rf_config['random_state'] = args.random_seed
-
-    # Use run.use_artifact(...).file() to get the train and validation artifact
-    # and save the returned path in train_local_pat
-    trainval_local_path = run.use_artifact(args.trainval_artifact).file()
-   
-    X = pd.read_csv(trainval_local_path)
-    y = X.pop("price")  # this removes the column "price" from X and puts it into y
-
-    logger.info(f"Minimum price: {y.min()}, Maximum price: {y.max()}")
-
-    X_train, X_val, y_train, y_val = train_test_split(
-        X, y, test_size=args.val_size, stratify=X[args.stratify_by], random_state=args.random_seed
-    )
-
-    logger.info("Preparing sklearn pipeline")
-
-    sk_pipe, processed_features = get_inference_pipeline(rf_config, args.max_tfidf_features)
-
-    # Then fit it to the X_train, y_train data
-    logger.info("Fitting")
-
-    ######################################
-    # Fit the pipeline sk_pipe by calling the .fit method on X_train and y_train
-    # YOUR CODE HERE
-    ######################################
-
-    # Compute r2 and MAE
-    logger.info("Scoring")
-    r_squared = sk_pipe.score(X_val, y_val)
-
-    y_pred = sk_pipe.predict(X_val)
-    mae = mean_absolute_error(y_val, y_pred)
-
-    logger.info(f"Score: {r_squared}")
-    logger.info(f"MAE: {mae}")
-
-    logger.info("Exporting model")
-
-    # Save model package in the MLFlow sklearn format
-    if os.path.exists("random_forest_dir"):
-        shutil.rmtree("random_forest_dir")
-
-    ######################################
-    # Save the sk_pipe pipeline as a mlflow.sklearn model in the directory "random_forest_dir"
-    # HINT: use mlflow.sklearn.save_model
-    signature = mlflow.models.infer_signature(X_val, y_pred)
-    mlflow.sklearn.save_model(
-        # YOUR CODE HERE
-        signature = signature,
-        input_example = X_train.iloc[:5]
-    )
-    ######################################
-
-
-    # Upload the model we just exported to W&B
-    artifact = wandb.Artifact(
-        args.output_artifact,
-        type = 'model_export',
-        description = 'Trained ranfom forest artifact',
-        metadata = rf_config
-    )
-    artifact.add_dir('random_forest_dir')
-    run.log_artifact(artifact)
-
-    # Plot feature importance
-    fig_feat_imp = plot_feature_importance(sk_pipe, processed_features)
-
-    ######################################
-    # Here we save variable r_squared under the "r2" key
-    run.summary['r2'] = r_squared
-    # Now save the variable mae under the key "mae".
-    # YOUR CODE HERE
-    ######################################
-
-    # Upload to W&B the feture importance visualization
-    run.log(
-        {
-          "feature_importance": wandb.Image(fig_feat_imp),
-        }
-    )
-
-
-def plot_feature_importance(pipe, feat_names):
-    # We collect the feature importance for all non-nlp features first
-    feat_imp = pipe["random_forest"].feature_importances_[: len(feat_names)-1]
-    # For the NLP feature we sum across all the TF-IDF dimensions into a global
-    # NLP importance
-    nlp_importance = sum(pipe["random_forest"].feature_importances_[len(feat_names) - 1:])
-    feat_imp = np.append(feat_imp, nlp_importance)
-    fig_feat_imp, sub_feat_imp = plt.subplots(figsize=(10, 10))
-    # idx = np.argsort(feat_imp)[::-1]
-    sub_feat_imp.bar(range(feat_imp.shape[0]), feat_imp, color="r", align="center")
-    _ = sub_feat_imp.set_xticks(range(feat_imp.shape[0]))
-    _ = sub_feat_imp.set_xticklabels(np.array(feat_names), rotation=90)
-    fig_feat_imp.tight_layout()
-    return fig_feat_imp
-
-
-def get_inference_pipeline(rf_config, max_tfidf_features):
-    # Let's handle the categorical features first
-    # Ordinal categorical are categorical values for which the order is meaningful, for example
-    # for room type: 'Entire home/apt' > 'Private room' > 'Shared room'
-    ordinal_categorical = ["room_type"]
-    non_ordinal_categorical = ["neighbourhood_group"]
-    # NOTE: we do not need to impute room_type because the type of the room
-    # is mandatory on the websites, so missing values are not possible in production
-    # (nor during training). That is not true for neighbourhood_group
-    ordinal_categorical_preproc = OrdinalEncoder()
-
-    ######################################
-    # Build a pipeline with two steps:
-    # 1 - A SimpleImputer(strategy="most_frequent") to impute missing values
-    # 2 - A OneHotEncoder() step to encode the variable
-    non_ordinal_categorical_preproc = make_pipeline(
-        # YOUR CODE HERE
-    )
-    ######################################
-
-    # Let's impute the numerical columns to make sure we can handle missing values
-    # (note that we do not scale because the RF algorithm does not need that)
-    zero_imputed = [
-        "minimum_nights",
-        "number_of_reviews",
-        "reviews_per_month",
-        "calculated_host_listings_count",
-        "availability_365",
-        "longitude",
-        "latitude"
-    ]
-    zero_imputer = SimpleImputer(strategy="constant", fill_value=0)
-
-    # A MINIMAL FEATURE ENGINEERING step:
-    # we create a feature that represents the number of days passed since the last review
-    # First we impute the missing review date with an old date (because there hasn't been
-    # a review for a long time), and then we create a new feature from it,
-    date_imputer = make_pipeline(
-        SimpleImputer(strategy='constant', fill_value='2010-01-01'),
-        FunctionTransformer(delta_date_feature, check_inverse=False, validate=False)
-    )
-
-    # Some minimal NLP for the "name" column
-    reshape_to_1d = FunctionTransformer(np.reshape, kw_args={"newshape": -1})
-    name_tfidf = make_pipeline(
-        SimpleImputer(strategy="constant", fill_value=""),
-        reshape_to_1d,
-        TfidfVectorizer(
-            binary=False,
-            max_features=max_tfidf_features,
-            stop_words='english'
-        ),
-    )
-
-    # Let's put everything together
-    preprocessor = ColumnTransformer(
-        transformers=[
-            ("ordinal_cat", ordinal_categorical_preproc, ordinal_categorical),
-            ("non_ordinal_cat", non_ordinal_categorical_preproc, non_ordinal_categorical),
-            ("impute_zero", zero_imputer, zero_imputed),
-            ("transform_date", date_imputer, ["last_review"]),
-            ("transform_name", name_tfidf, ["name"])
-        ],
-        remainder="drop",  # This drops the columns that we do not transform
-    )
-
-    processed_features = ordinal_categorical + non_ordinal_categorical + zero_imputed + ["last_review", "name"]
-
-    # Create random forest
-    random_forest = RandomForestRegressor(**rf_config)
-
-    ######################################
-    # Create the inference pipeline. The pipeline must have 2 steps: 
-    # 1 - a step called "preprocessor" applying the ColumnTransformer instance that we saved in the `preprocessor` variable
-    # 2 - a step called "random_forest" with the random forest instance that we just saved in the `random_forest` variable.
-    # HINT: Use the explicit Pipeline constructor so you can assign the names to the steps, do not use make_pipeline
-
-    sk_pipe = Pipeline(
-        steps =[
-        # YOUR CODE HERE
-        ]
-    )
-
-    return sk_pipe, processed_features
-    ######################################
-
-
-if __name__ == "__main__":
-
-    parser = argparse.ArgumentParser(description="Basic cleaning of dataset")
-
-    parser.add_argument(
-        "--trainval_artifact",
-        type=str,
-        help="Artifact containing the training dataset. It will be split into train and validation"
-    )
-
-    parser.add_argument(
-        "--val_size",
-        type=float,
-        help="Size of the validation split. Fraction of the dataset, or number of items",
-    )
-
-    parser.add_argument(
-        "--random_seed",
-        type=int,
-        help="Seed for random number generator",
-        default=42,
-        required=False,
-    )
-
-    parser.add_argument(
-        "--stratify_by",
-        type=str,
-        help="Column to use for stratification",
-        default="none",
-        required=False,
-    )
-
-    parser.add_argument(
-        "--rf_config",
-        help="Random forest configuration. A JSON dict that will be passed to the "
-        "scikit-learn constructor for RandomForestRegressor.",
-        default="{}",
-    )
-
-    parser.add_argument(
-        "--max_tfidf_features",
-        help="Maximum number of words to consider for the TFIDF",
-        default=10,
-        type=int
-    )
-
-    parser.add_argument(
-        "--output_artifact",
-        type=str,
-        help="Name for the output serialized model",
-        required=True,
-    )
-
-    args = parser.parse_args()
-
-    go(args)
+#!/usr/bin/env python
+"""
+This script trains a Random Forest
+"""
+import argparse
+import logging
+import os
+import shutil
+import matplotlib.pyplot as plt
+
+import mlflow
+from mlflow.models import infer_signature
+
+import json
+
+import pandas as pd
+import numpy as np
+from sklearn.compose import ColumnTransformer
+from sklearn.feature_extraction.text import TfidfVectorizer
+from sklearn.impute import SimpleImputer
+from sklearn.model_selection import train_test_split
+from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer
+
+import wandb
+from sklearn.ensemble import RandomForestRegressor
+from sklearn.metrics import mean_absolute_error
+from sklearn.pipeline import Pipeline, make_pipeline
+
+
+def delta_date_feature(dates):
+    """
+    Given a 2d array containing dates (in any format recognized by pd.to_datetime), it returns the delta in days
+    between each date and the most recent date in its column
+    """
+    date_sanitized = pd.DataFrame(dates).apply(pd.to_datetime)
+    return date_sanitized.apply(lambda d: (d.max() -d).dt.days, axis=0).to_numpy()
+
+
+logging.basicConfig(level=logging.INFO, format="%(asctime)-15s %(message)s")
+logger = logging.getLogger()
+
+
+def go(args):
+
+    run = wandb.init(job_type="train_random_forest")
+    run.config.update(args)
+
+    # Get the Random Forest configuration and update W&B
+    with open(args.rf_config) as fp:
+        rf_config = json.load(fp)
+    run.config.update(rf_config)
+
+    # Fix the random seed for the Random Forest, so we get reproducible results
+    rf_config['random_state'] = args.random_seed
+
+    # Use run.use_artifact(...).file() to get the train and validation artifact
+    # and save the returned path in train_local_pat
+    trainval_local_path = run.use_artifact(args.trainval_artifact).file()
+   
+    X = pd.read_csv(trainval_local_path)
+    y = X.pop("price")  # this removes the column "price" from X and puts it into y
+
+    logger.info(f"Minimum price: {y.min()}, Maximum price: {y.max()}")
+
+    X_train, X_val, y_train, y_val = train_test_split(
+        X, y, test_size=args.val_size, stratify=X[args.stratify_by], random_state=args.random_seed
+    )
+
+    logger.info("Preparing sklearn pipeline")
+
+    sk_pipe, processed_features = get_inference_pipeline(rf_config, args.max_tfidf_features)
+
+    # Then fit it to the X_train, y_train data
+    logger.info("Fitting")
+
+    ######################################
+    # Fit the pipeline sk_pipe by calling the .fit method on X_train and y_train
+    sk_pipe.fit(X_train, y_train)
+    ######################################
+
+    # Compute r2 and MAE
+    logger.info("Scoring")
+    r_squared = sk_pipe.score(X_val, y_val)
+
+    y_pred = sk_pipe.predict(X_val)
+    mae = mean_absolute_error(y_val, y_pred)
+
+    logger.info(f"Score: {r_squared}")
+    logger.info(f"MAE: {mae}")
+
+    logger.info("Exporting model")
+
+    # Save model package in the MLFlow sklearn format
+    if os.path.exists("random_forest_dir"):
+        shutil.rmtree("random_forest_dir")
+
+    ######################################
+    # Save the sk_pipe pipeline as a mlflow.sklearn model in the directory "random_forest_dir"
+    # HINT: use mlflow.sklearn.save_ature = mlflow.models.infer_signature(X_val, y_pred)
+    signature = infer_signature(X_val, y_pred)
+    mlflow.sklearn.save_model(
+        sk_pipe,  
+        path="random_forest_dir",  
+        serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE,
+        signature=signature,
+        input_example=X_train.iloc[:5]
+    )
+    ######################################
+
+
+    # Upload the model we just exported to W&B
+    artifact = wandb.Artifact(
+        args.output_artifact,
+        type = 'model_export',
+        description = 'Trained ranfom forest artifact',
+        metadata = rf_config
+    )
+    artifact.add_dir('random_forest_dir')
+    run.log_artifact(artifact)
+
+    # Plot feature importance
+    fig_feat_imp = plot_feature_importance(sk_pipe, processed_features)
+
+    ######################################
+    # Here we save variable r_squared under the "r2" key
+    run.summary['r2'] = r_squared
+    # Now save the variable mae under the key "mae".
+    run.summary['mae'] = mae
+    ######################################
+
+    # Upload to W&B the feture importance visualization
+    run.log(
+        {
+          "feature_importance": wandb.Image(fig_feat_imp),
+        }
+    )
+
+
+def plot_feature_importance(pipe, feat_names):
+    # We collect the feature importance for all non-nlp features first
+    feat_imp = pipe["random_forest"].feature_importances_[: len(feat_names)-1]
+    # For the NLP feature we sum across all the TF-IDF dimensions into a global
+    # NLP importance
+    nlp_importance = sum(pipe["random_forest"].feature_importances_[len(feat_names) - 1:])
+    feat_imp = np.append(feat_imp, nlp_importance)
+    fig_feat_imp, sub_feat_imp = plt.subplots(figsize=(10, 10))
+    # idx = np.argsort(feat_imp)[::-1]
+    sub_feat_imp.bar(range(feat_imp.shape[0]), feat_imp, color="r", align="center")
+    _ = sub_feat_imp.set_xticks(range(feat_imp.shape[0]))
+    _ = sub_feat_imp.set_xticklabels(np.array(feat_names), rotation=90)
+    fig_feat_imp.tight_layout()
+    return fig_feat_imp
+
+
+def get_inference_pipeline(rf_config, max_tfidf_features):
+    # Let's handle the categorical features first
+    # Ordinal categorical are categorical values for which the order is meaningful, for example
+    # for room type: 'Entire home/apt' > 'Private room' > 'Shared room'
+    ordinal_categorical = ["room_type"]
+    non_ordinal_categorical = ["neighbourhood_group"]
+    # NOTE: we do not need to impute room_type because the type of the room
+    # is mandatory on the websites, so missing values are not possible in production
+    # (nor during training). That is not true for neighbourhood_group
+    ordinal_categorical_preproc = OrdinalEncoder()
+
+    ######################################
+    # Build a pipeline with two steps:
+    # 1 - A SimpleImputer(strategy="most_frequent") to impute missing values
+    # 2 - A OneHotEncoder() step to encode the variable
+    non_ordinal_categorical_preproc = make_pipeline(
+        SimpleImputer(strategy="most_frequent"), OneHotEncoder()
+    )
+    ######################################
+
+    # Let's impute the numerical columns to make sure we can handle missing values
+    # (note that we do not scale because the RF algorithm does not need that)
+    zero_imputed = [
+        "minimum_nights",
+        "number_of_reviews",
+        "reviews_per_month",
+        "calculated_host_listings_count",
+        "availability_365",
+        "longitude",
+        "latitude"
+    ]
+    zero_imputer = SimpleImputer(strategy="constant", fill_value=0)
+
+    # A MINIMAL FEATURE ENGINEERING step:
+    # we create a feature that represents the number of days passed since the last review
+    # First we impute the missing review date with an old date (because there hasn't been
+    # a review for a long time), and then we create a new feature from it,
+    date_imputer = make_pipeline(
+        SimpleImputer(strategy='constant', fill_value='2010-01-01'),
+        FunctionTransformer(delta_date_feature, check_inverse=False, validate=False)
+    )
+
+    # Some minimal NLP for the "name" column
+    reshape_to_1d = FunctionTransformer(np.reshape, kw_args={"newshape": -1})
+    name_tfidf = make_pipeline(
+        SimpleImputer(strategy="constant", fill_value=""),
+        reshape_to_1d,
+        TfidfVectorizer(
+            binary=False,
+            max_features=max_tfidf_features,
+            stop_words='english'
+        ),
+    )
+
+    # Let's put everything together
+    preprocessor = ColumnTransformer(
+        transformers=[
+            ("ordinal_cat", ordinal_categorical_preproc, ordinal_categorical),
+            ("non_ordinal_cat", non_ordinal_categorical_preproc, non_ordinal_categorical),
+            ("impute_zero", zero_imputer, zero_imputed),
+            ("transform_date", date_imputer, ["last_review"]),
+            ("transform_name", name_tfidf, ["name"])
+        ],
+        remainder="drop",  # This drops the columns that we do not transform
+    )
+
+    processed_features = ordinal_categorical + non_ordinal_categorical + zero_imputed + ["last_review", "name"]
+
+    # Create random forest
+    random_forest = RandomForestRegressor(**rf_config)
+
+    ######################################
+    # Create the inference pipeline. The pipeline must have 2 steps: 
+    # 1 - a step called "preprocessor" applying the ColumnTransformer instance that we saved in the `preprocessor` variable
+    # 2 - a step called "random_forest" with the random forest instance that we just saved in the `random_forest` variable.
+    # HINT: Use the explicit Pipeline constructor so you can assign the names to the steps, do not use make_pipeline
+
+    sk_pipe = Pipeline(
+        steps =[
+        ("preprocessor", preprocessor),
+        ("random_forest", random_forest)
+        ]
+    )
+
+    return sk_pipe, processed_features
+    ######################################
+
+
+if __name__ == "__main__":
+
+    parser = argparse.ArgumentParser(description="Basic cleaning of dataset")
+
+    parser.add_argument(
+        "--trainval_artifact",
+        type=str,
+        help="Artifact containing the training dataset. It will be split into train and validation"
+    )
+
+    parser.add_argument(
+        "--val_size",
+        type=float,
+        help="Size of the validation split. Fraction of the dataset, or number of items",
+    )
+
+    parser.add_argument(
+        "--random_seed",
+        type=int,
+        help="Seed for random number generator",
+        default=42,
+        required=False,
+    )
+
+    parser.add_argument(
+        "--stratify_by",
+        type=str,
+        help="Column to use for stratification",
+        default="none",
+        required=False,
+    )
+
+    parser.add_argument(
+        "--rf_config",
+        help="Random forest configuration. A JSON dict that will be passed to the "
+        "scikit-learn constructor for RandomForestRegressor.",
+        default="{}",
+    )
+
+    parser.add_argument(
+        "--max_tfidf_features",
+        help="Maximum number of words to consider for the TFIDF",
+        default=10,
+        type=int
+    )
+
+    parser.add_argument(
+        "--output_artifact",
+        type=str,
+        help="Name for the output serialized model",
+        required=True,
+    )
+
+    args = parser.parse_args()
+
+    go(args)
